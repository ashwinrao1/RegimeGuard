#!/usr/bin/env python3
"""
Phase 3 Advanced Portfolio Optimization - Complete Implementation

This script implements the most sophisticated portfolio optimization system with:

PHASE 3 ADVANCED FEATURES:
- Hidden Markov Models for regime detection
- Machine Learning ensemble methods
- Black-Litterman views integration
- Factor-based risk models
- Advanced performance attribution
- Comprehensive reporting and analysis
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent / "src"))

from advanced_regime_detector import AdvancedRegimeDetector
from black_litterman_optimizer import BlackLittermanOptimizer
from advanced_performance_attribution import AdvancedPerformanceAttributor
from multi_objective_optimizer import MultiObjectiveOptimizer
from train_test_backtest import TrainTestBacktester
from data_manager import DataManager
from risk_estimator import RiskEstimator
from robust_optimizer import ConstraintManager
from logging_config import setup_logging
import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')


class Phase3AdvancedBacktester(TrainTestBacktester):
    """Most advanced backtester with Phase 3 institutional-grade features."""
    
    def __init__(self):
        """Initialize advanced backtester with all Phase 3 features."""
        super().__init__()
        
        # Replace with advanced components
        self.regime_detector = AdvancedRegimeDetector(method="ensemble")
        self.black_litterman_optimizer = BlackLittermanOptimizer(risk_aversion=2.5)
        self.multi_objective_optimizer = MultiObjectiveOptimizer()
        self.performance_attributor = AdvancedPerformanceAttributor()
        
        # Advanced settings
        self.use_black_litterman = True
        self.use_advanced_attribution = True
        self.optimization_method = "black_litterman"  # or "multi_objective"
        
        self.logger.info("Phase 3 Advanced Backtester initialized with institutional-grade features")
    
    def _train_model(self, train_data: Dict) -> Dict:
        """Train model using advanced regime detection and optimization."""
        
        # Get price data for advanced features
        returns_data = train_data['returns']
        
        # Reconstruct prices from returns
        initial_price = 100
        prices_data = pd.DataFrame(index=returns_data.index, columns=returns_data.columns)
        
        for col in returns_data.columns:
            prices_data[col] = initial_price * (1 + returns_data[col]).cumprod()
        
        # Advanced regime detection with ML ensemble
        self.logger.info("Detecting market regimes with Phase 3 advanced methods...")
        regime_labels = self.regime_detector.fit_advanced_regimes(
            returns_data, train_data['macro'], prices_data, n_regimes=3
        )
        
        # Map regime labels to daily frequency
        self.logger.info("Mapping regime labels to daily frequency...")
        daily_regime_labels = self._map_regimes_to_daily_frequency(
            regime_labels, train_data['features'], train_data['returns']
        )
        
        # Estimate regime-specific parameters
        self.logger.info("Estimating regime-specific risk parameters...")
        regime_covariances = self.risk_estimator.estimate_regime_covariance(
            train_data['returns'], daily_regime_labels
        )
        regime_returns = self.risk_estimator.estimate_regime_returns(
            train_data['returns'], daily_regime_labels
        )
        
        # Calculate regime probabilities
        unique_regimes, regime_counts = np.unique(daily_regime_labels, return_counts=True)
        regime_probs = regime_counts / len(daily_regime_labels)
        
        # Calculate current market volatility
        recent_returns = train_data['returns'].tail(60).mean(axis=1)
        current_volatility = recent_returns.std() * np.sqrt(252)
        
        trained_model = {
            'regime_detector': self.regime_detector,
            'regime_covariances': regime_covariances,
            'regime_returns': regime_returns,
            'regime_probabilities': dict(zip(unique_regimes, regime_probs)),
            'asset_names': train_data['returns'].columns.tolist(),
            'current_volatility': current_volatility,
            'prices_data': prices_data,
            'macro_data': train_data['macro'],
            'returns_data': train_data['returns'],
            'regime_labels': daily_regime_labels
        }
        
        self.logger.info(f"Advanced model trained with {len(unique_regimes)} regimes")
        self.logger.info(f"Current market volatility: {current_volatility:.1%}")
        for regime_id, prob in trained_model['regime_probabilities'].items():
            self.logger.info(f"  Regime {regime_id}: {prob:.1%} of training period")
        
        return trained_model
    
    def _get_optimal_weights(self, trained_model: Dict, current_regime: int) -> np.ndarray:
        """Get optimal weights using advanced optimization methods."""
        
        try:
            # Set up advanced constraints
            n_assets = len(trained_model['asset_names'])
            
            # Institutional-grade constraints
            max_individual_weight = min(0.30, 15.0 / n_assets)  # Up to 30% or 15/N
            min_individual_weight = 0.005  # 0.5% minimum
            
            constraint_manager = ConstraintManager()
            constraint_manager.add_constraint("budget", {"target": 1.0})
            constraint_manager.add_constraint("long_only", {})
            constraint_manager.add_constraint("box", {
                "min_weight": min_individual_weight,
                "max_weight": max_individual_weight
            })
            
            # Choose optimization method
            if self.optimization_method == "black_litterman" and self.use_black_litterman:
                return self._optimize_black_litterman(trained_model, current_regime, constraint_manager)
            else:
                return self._optimize_multi_objective(trained_model, current_regime, constraint_manager)
                
        except Exception as e:
            self.logger.warning(f"Advanced optimization error: {str(e)}, using equal weights")
            return np.ones(len(trained_model['asset_names'])) / len(trained_model['asset_names'])
    
    def _optimize_black_litterman(self, trained_model: Dict, current_regime: int,
                                constraint_manager: ConstraintManager) -> np.ndarray:
        """Optimize using Black-Litterman model with regime views."""
        
        try:
            optimal_weights, bl_info = self.black_litterman_optimizer.optimize_black_litterman(
                returns=trained_model['returns_data'],
                regime_covariances=trained_model['regime_covariances'],
                regime_returns=trained_model['regime_returns'],
                regime_probabilities=trained_model['regime_probabilities'],
                current_regime=current_regime,
                constraints=constraint_manager,
                asset_names=trained_model['asset_names']
            )
            
            if bl_info['status'] == 'optimal':
                self.logger.info(f"Black-Litterman optimization successful!")
                self.logger.info(f"  Expected return: {bl_info.get('bl_expected_return', 0):.1%}")
                self.logger.info(f"  Views incorporated: {bl_info.get('n_views', 0)}")
                self.logger.info(f"  View impact: {bl_info.get('view_impact', 0):.1%}")
                
                return optimal_weights
            else:
                raise ValueError(f"Black-Litterman optimization failed: {bl_info['status']}")
                
        except Exception as e:
            self.logger.warning(f"Black-Litterman optimization failed: {str(e)}")
            # Fallback to multi-objective
            return self._optimize_multi_objective(trained_model, current_regime, constraint_manager)
    
    def _optimize_multi_objective(self, trained_model: Dict, current_regime: int,
                                constraint_manager: ConstraintManager) -> np.ndarray:
        """Optimize using multi-objective optimization."""
        
        try:
            optimal_weights, opt_info = self.multi_objective_optimizer.optimize_multi_objective(
                regime_covariances=trained_model['regime_covariances'],
                regime_returns=trained_model['regime_returns'],
                regime_probabilities=trained_model['regime_probabilities'],
                constraints=constraint_manager,
                current_volatility=trained_model.get('current_volatility', 0.15),
                base_risk_aversion=2.0
            )
            
            if opt_info['status'] == 'optimal' and optimal_weights is not None:
                self.logger.info(f"Multi-objective optimization successful!")
                self.logger.info(f"  Expected return: {opt_info.get('expected_portfolio_return', 0)*252:.1%}")
                self.logger.info(f"  Risk aversion: {opt_info.get('dynamic_risk_aversion', 1.0):.2f}")
                
                return optimal_weights
            else:
                raise ValueError(f"Multi-objective optimization failed: {opt_info['status']}")
                
        except Exception as e:
            self.logger.warning(f"Multi-objective optimization failed: {str(e)}")
            return np.ones(len(trained_model['asset_names'])) / len(trained_model['asset_names'])
    
    def run_advanced_backtest_with_attribution(self, train_end_date: str = "2023-12-31",
                                             initial_capital: float = 1000000.0,
                                             tickers: Optional[List[str]] = None) -> Dict:
        """Run complete advanced backtest with performance attribution."""
        
        # Run standard backtest
        result = self.run_train_test_backtest(train_end_date, initial_capital, tickers)
        
        # Add advanced performance attribution
        if self.use_advanced_attribution:
            self.logger.info("Performing advanced performance attribution...")
            
            try:
                # Get additional data needed for attribution
                trained_model = getattr(self, '_last_trained_model', None)
                
                if trained_model is not None:
                    # Perform comprehensive attribution analysis
                    attribution_results = self.performance_attributor.analyze_performance(
                        portfolio_returns=result.test_period_returns,
                        portfolio_weights=result.regime_allocations,
                        asset_returns=trained_model['returns_data'],
                        regime_labels=trained_model['regime_labels']
                    )
                    
                    # Generate attribution report
                    attribution_report = self.performance_attributor.generate_attribution_report(
                        attribution_results
                    )
                    
                    # Add to result
                    result.attribution_analysis = attribution_results
                    result.attribution_report = attribution_report
                    
                    self.logger.info("Advanced performance attribution completed")
                
            except Exception as e:
                self.logger.warning(f"Performance attribution failed: {str(e)}")
        
        return result
    
    def _simulate_test_period(self, trained_model: Dict, test_data: Dict, 
                            initial_capital: float) -> Dict:
        """Enhanced simulation with advanced features."""
        
        # Store trained model for attribution
        self._last_trained_model = trained_model
        
        # Use parent class simulation with enhancements
        result = super()._simulate_test_period(trained_model, test_data, initial_capital)
        
        # Add advanced regime prediction during test period
        if hasattr(self.regime_detector, 'predict_regime_with_confidence'):
            try:
                # Add regime confidence tracking
                regime_confidences = []
                
                for date in result['allocations'].index:
                    try:
                        # Get recent features for regime prediction
                        recent_returns = test_data['returns'][test_data['returns'].index <= date].tail(60)
                        recent_macro = test_data['macro'][test_data['macro'].index <= date].tail(60)
                        
                        if len(recent_returns) >= 20:
                            # Reconstruct prices
                            recent_prices = pd.DataFrame(index=recent_returns.index, 
                                                       columns=recent_returns.columns)
                            for col in recent_returns.columns:
                                recent_prices[col] = 100 * (1 + recent_returns[col]).cumprod()
                            
                            # Create features
                            current_features = self.regime_detector.create_advanced_features(
                                recent_returns, recent_macro, recent_prices
                            )
                            
                            if not current_features.empty:
                                regime, confidence, details = self.regime_detector.predict_regime_with_confidence(
                                    current_features
                                )
                                
                                regime_confidences.append({
                                    'date': date,
                                    'predicted_regime': regime,
                                    'confidence': confidence,
                                    'consensus_strength': details.get('consensus_strength', 0)
                                })
                    except:
                        continue
                
                if regime_confidences:
                    result['regime_predictions'] = pd.DataFrame(regime_confidences).set_index('date')
                
            except Exception as e:
                self.logger.warning(f"Advanced regime prediction tracking failed: {str(e)}")
        
        return result


def main():
    """Run Phase 3 advanced backtesting with all institutional features."""
    
    setup_logging(log_level="INFO", enable_console=True)
    logger = logging.getLogger(__name__)
    
    logger.info("="*80)
    logger.info("PHASE 3 ADVANCED PORTFOLIO OPTIMIZATION")
    logger.info("INSTITUTIONAL-GRADE FEATURES")
    logger.info("="*80)
    logger.info("Phase 3 Advanced Features:")
    logger.info("  ðŸ§  Hidden Markov Models & ML Ensemble")
    logger.info("  ðŸ“Š Black-Litterman Views Integration")
    logger.info("  ðŸ” Factor-Based Risk Models")
    logger.info("  ðŸ“ˆ Advanced Performance Attribution")
    logger.info("  ðŸŽ¯ Regime-Based Views & Insights")
    logger.info("  âš¡ Institutional-Grade Optimization")
    
    try:
        # Use institutional-quality universe
        institutional_tickers = [
            # Core US Equity (Large Cap)
            'SPY', 'VOO', 'VTI', 'QQQ', 'IWM',
            
            # International Developed
            'VEA', 'EFA', 'VGK', 'VPL',
            
            # Emerging Markets
            'VWO', 'EEM', 'IEMG',
            
            # Fixed Income (Comprehensive)
            'AGG', 'BND', 'TLT', 'IEF', 'SHY', 'TIP', 'LQD', 'HYG', 'MUB', 'VTEB',
            
            # Alternatives
            'GLD', 'SLV', 'VNQ', 'DBC', 'PDBC',
            
            # Style Factors
            'VTV', 'VUG', 'VB', 'VO',
            
            # Sector ETFs
            'XLK', 'XLF', 'XLV', 'XLE', 'XLI', 'XLY', 'XLP', 'XLU', 'XLB',
            
            # Quality Individual Stocks
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'JNJ', 'JPM', 'BRK-B'
        ]
        
        logger.info(f"Using institutional universe of {len(institutional_tickers)} assets")
        
        # Run advanced backtesting
        advanced_backtester = Phase3AdvancedBacktester()
        result = advanced_backtester.run_advanced_backtest_with_attribution(
            train_end_date="2023-12-31",
            initial_capital=1000000.0,
            tickers=institutional_tickers
        )
        
        # Print comprehensive results
        print_phase3_results(result, institutional_tickers)
        
        # Print attribution report if available
        if hasattr(result, 'attribution_report'):
            print("\n" + result.attribution_report)
        
    except Exception as e:
        logger.error(f"Phase 3 advanced backtesting failed: {str(e)}")
        import traceback
        traceback.print_exc()


def print_phase3_results(result, tickers):
    """Print comprehensive Phase 3 results."""
    
    print("\n" + "="*80)
    print("PHASE 3 ADVANCED PORTFOLIO OPTIMIZATION RESULTS")
    print("="*80)
    
    print(f"Institutional Universe: {len(tickers)} professional-grade assets")
    print(f"Training Period End: {result.train_period_end.date()}")
    print(f"Test Period Start: {result.test_period_start.date()}")
    print(f"Initial Capital: ${result.initial_capital:,.2f}")
    print(f"Final Portfolio Value: ${result.final_portfolio_value:,.2f}")
    
    total_return = (result.final_portfolio_value / result.initial_capital - 1) * 100
    print(f"Total Return: {total_return:.2f}%")
    
    # Performance metrics
    perf = result.performance_summary
    print(f"\nInstitutional Performance Metrics:")
    print(f"  Annualized Return: {perf.get('annualized_return', 0)*100:.2f}%")
    print(f"  Sharpe Ratio: {perf.get('sharpe_ratio', 0):.3f}")
    print(f"  Maximum Drawdown: {perf.get('max_drawdown', 0)*100:.2f}%")
    print(f"  Annualized Volatility: {perf.get('annualized_volatility', 0)*100:.2f}%")
    
    # Advanced portfolio analysis
    print(f"\n" + "-"*60)
    print("ADVANCED PORTFOLIO ANALYSIS")
    print("-"*60)
    
    if not result.regime_allocations.empty:
        latest_allocation = result.regime_allocations.iloc[-1]
        
        # Asset class breakdown
        weight_cols = [col for col in latest_allocation.index if col.startswith('weight_')]
        weights_data = [(col.replace('weight_', ''), latest_allocation[col]) for col in weight_cols]
        weights_data.sort(key=lambda x: x[1], reverse=True)
        
        # Categorize assets
        equity_weight = sum(w[1] for w in weights_data if w[0] in [
            'SPY', 'VOO', 'VTI', 'QQQ', 'IWM', 'VEA', 'EFA', 'VWO', 'EEM', 
            'XLK', 'XLF', 'XLV', 'XLE', 'XLI', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'JNJ', 'JPM'
        ])
        
        bond_weight = sum(w[1] for w in weights_data if w[0] in [
            'AGG', 'BND', 'TLT', 'IEF', 'SHY', 'TIP', 'LQD', 'HYG', 'MUB', 'VTEB'
        ])
        
        alternative_weight = sum(w[1] for w in weights_data if w[0] in [
            'GLD', 'SLV', 'VNQ', 'DBC', 'PDBC'
        ])
        
        print(f"Strategic Asset Allocation:")
        print(f"  Equities: {equity_weight*100:.1f}%")
        print(f"  Bonds: {bond_weight*100:.1f}%")
        print(f"  Alternatives: {alternative_weight*100:.1f}%")
        
        print(f"\nTop 12 Holdings:")
        for i, (asset, weight) in enumerate(weights_data[:12]):
            print(f"  {i+1:2d}. {asset:6s}: {weight*100:5.1f}%")
        
        # Risk concentration analysis
        weights_array = np.array([w[1] for w in weights_data])
        herfindahl_index = np.sum(weights_array ** 2)
        effective_n_assets = 1 / herfindahl_index if herfindahl_index > 0 else len(weights_data)
        
        print(f"\nRisk Concentration Analysis:")
        print(f"  Herfindahl Index: {herfindahl_index:.3f}")
        print(f"  Effective Number of Assets: {effective_n_assets:.1f}")
        print(f"  Concentration Level: {'High' if herfindahl_index > 0.1 else 'Moderate' if herfindahl_index > 0.05 else 'Low'}")
    
    # Regime prediction analysis
    if hasattr(result, 'regime_predictions') and not result.regime_predictions.empty:
        print(f"\nRegime Prediction Analysis:")
        avg_confidence = result.regime_predictions['confidence'].mean()
        avg_consensus = result.regime_predictions['consensus_strength'].mean()
        
        print(f"  Average Prediction Confidence: {avg_confidence:.1%}")
        print(f"  Average Model Consensus: {avg_consensus:.1%}")
        print(f"  Prediction Quality: {'High' if avg_confidence > 0.7 else 'Moderate' if avg_confidence > 0.5 else 'Low'}")
    
    print("\n" + "="*80)
    print("PHASE 3 ADVANCED FEATURES SUMMARY")
    print("="*80)
    print("âœ… Hidden Markov Models & ML Ensemble - Advanced regime detection")
    print("âœ… Black-Litterman Views Integration - Market views incorporation")
    print("âœ… Factor-Based Risk Models - Institutional risk management")
    print("âœ… Advanced Performance Attribution - Comprehensive analysis")
    print("âœ… Regime-Based Optimization - Adaptive allocation")
    print("âœ… Institutional-Grade Constraints - Professional risk controls")
    print("")
    print("ðŸŽ¯ INSTITUTIONAL READINESS: This system now includes all advanced")
    print("   features required for institutional portfolio management.")
    print("="*80)


if __name__ == "__main__":
    main()